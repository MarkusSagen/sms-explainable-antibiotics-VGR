{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import shap\n",
    "import argparse\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForPreTraining,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AlbertForSequenceClassification,\n",
    "    MT5ForConditionalGeneration,\n",
    "    AutoModelWithLMHead,\n",
    "    AutoTokenizer,\n",
    "    AlbertTokenizer,\n",
    "    T5Tokenizer,\n",
    "    PretrainedConfig,\n",
    "    PreTrainedTokenizer,\n",
    ")\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerIntegratedGradients, GradientShap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-floor",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kb_bert = 'KB/bert-base-swedish-cased'\n",
    "kb_bert = 'bert-base-multilingual-cased'\n",
    "#kb_bert = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(kb_bert)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(kb_bert)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"../models/\"+kb_bert+\"_ft.pt\"))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "vis_data_records = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-poison",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_dataset(\"csv\", data_files='../data/test2.csv')\n",
    "train_dataset = load_dataset(\"csv\", data_files='../data/train2.csv')\n",
    "#test_dataset = load_dataset(\"csv\", data_files='../data/test2_names.csv')\n",
    "#train_dataset = load_dataset(\"csv\", data_files='../data/train2_names.csv')\n",
    "\n",
    "test_ind = test_dataset\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], max_length = 512, add_special_tokens = True)\n",
    "\n",
    "test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-picking",
   "metadata": {},
   "source": [
    "## Prediction for SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(input_ids, attention_mask=None, batch_size=64, label=None,\n",
    "               output_logits=False):\n",
    "    \"\"\"\n",
    "    Wrapper function for a Huggingface Transformers model into the format that KernelSHAP expects,\n",
    "    i.e. where inputs and outputs are numpy arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    input_ids = torch.tensor(input_ids, device=device)\n",
    "    attention_mask = torch.ones_like(input_ids, device=device) if attention_mask is None else torch.tensor(attention_mask, device=device)\n",
    "\n",
    "    ds = torch.utils.data.TensorDataset(input_ids.long(), attention_mask.long())\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_size=batch_size)\n",
    "    probas = []\n",
    "    logits = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            out = model(batch[0], attention_mask=batch[1])\n",
    "            logits.append(out[0].clone().detach())\n",
    "            probas.append(torch.nn.functional.softmax(out[0],\n",
    "                                                      dim=1).detach())\n",
    "    logits = torch.cat(logits, dim=0).detach().cpu().clone().numpy()\n",
    "    probas = torch.cat(probas, dim=0).detach().cpu().clone().numpy()\n",
    "\n",
    "    if label is not None:\n",
    "        probas = probas[:, label]\n",
    "        logits = logits[:, label]\n",
    "\n",
    "    return (probas, logits) if output_logits else probas\n",
    "\n",
    "\n",
    "def tokens2words(tokens, seq, token_prefix=\"##\"):\n",
    "    \"\"\"\n",
    "    Utility function to aggregate 'seq' on word-level based on 'tokens'\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = []\n",
    "    for token, x in zip(tokens, seq):\n",
    "        if token.startswith(token_prefix):\n",
    "            if type(x) == str:\n",
    "                x = x.replace(token_prefix,\"\")\n",
    "            tmp[-1] += x\n",
    "        else:\n",
    "            if type(x) == str:\n",
    "                tmp.append(x)\n",
    "            else:\n",
    "                tmp.append(x.item())\n",
    "\n",
    "    return tmp if type(tmp[-1]) == str else torch.tensor(tmp, device=device)\n",
    "\n",
    "def tokens2wordssentence(tokens, seq, token_prefix=\"â–\"):\n",
    "    \"\"\"\n",
    "    Utility function to aggregate 'seq' on word-level based on 'tokens'\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = []\n",
    "    for token, x in zip(tokens, seq):\n",
    "        if token.startswith(token_prefix):\n",
    "            if type(x) == str:\n",
    "                x = x.replace(token_prefix,\" \")\n",
    "            if type(x) == str:\n",
    "                tmp.append(x)\n",
    "            else:\n",
    "                tmp.append(x.item())\n",
    "                \n",
    "        elif not token.startswith(\" \"):\n",
    "            if type(x) == str:\n",
    "                x = x.replace(\" \",\"\")\n",
    "            if len(tmp)>0:\n",
    "                tmp[-1] += x\n",
    "        else:\n",
    "            if type(x) == str:\n",
    "                tmp.append(x)\n",
    "            else:\n",
    "                tmp.append(x.item())\n",
    "                \n",
    "    if len(tmp)==0:\n",
    "        print(tokens,tmp)\n",
    "    \n",
    "    return tmp if type(tmp[-1]) == str else torch.tensor(tmp, device=device)\n",
    "\n",
    "def add_attributions_to_visualizer(attributions, pred, pred_ind, label, tokens, delta, vis_data_records):\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    vis_data_records.append(viz.VisualizationDataRecord(\n",
    "                            attributions/attributions.norm(),\n",
    "                            pred,\n",
    "                            pred_ind,\n",
    "                            label,\n",
    "                            pred_ind,\n",
    "                            attributions.sum(),       \n",
    "                            tokens,\n",
    "                            delta)) \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-malaysia",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 1000\n",
    "\n",
    "idx = np.random.choice(len(test_dataset['train']))\n",
    "#idx = 20\n",
    "#idx = 183\n",
    "#idx = 471\n",
    "#idx = 1469//872\n",
    "#idx = 4625\n",
    "\n",
    "#idx = 295\n",
    "#idx = 1881\n",
    "idx = 58\n",
    "print(idx)\n",
    "ref_token = tokenizer.pad_token_id # Could also consider <UNK> or <MASK> tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_x = train_dataset['train']\n",
    "input_x = test_dataset['train']\n",
    "input_text = input_x['text'][idx]\n",
    "label = input_x['label'][idx]\n",
    "input_ids = input_x['input_ids'][idx].unsqueeze(0)\n",
    "attention_mask = input_x['attention_mask'][idx].unsqueeze(0)\n",
    "\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "input_words = tokens2words(input_tokens, input_tokens)\n",
    "pred = predict_fn(input_ids=input_ids)\n",
    "pred_label = pred.argmax()\n",
    "pred_p = pred[0, pred_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = input_ids.detach().cpu().clone().numpy()\n",
    "\n",
    "# Keep CLS and SEP tokens fixed in baseline\n",
    "baseline[:,1:-1] = ref_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn_label = functools.partial(predict_fn, label=pred_label)\n",
    "\n",
    "explainer = shap.KernelExplainer(predict_fn_label, baseline)\n",
    "\n",
    "phi = explainer.shap_values(input_ids.detach().cpu().clone().numpy(), nsamples=nsamples)\n",
    "phi_words = tokens2words(input_tokens, phi.squeeze())\n",
    "\n",
    "phi.shape\n",
    "explainer.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_attributions_to_visualizer(phi_words, pred_p, pred_label, label, input_words, None, vis_data_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.visualize_text(vis_data_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-stock",
   "metadata": {},
   "source": [
    "## Integrated Gradiente (IG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModelWrapper(nn.Module):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        super(BertModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, input_ids):        \n",
    "        outputs = self.model(input_ids=input_ids)\n",
    "        logits = outputs.logits\n",
    "        return nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "def tokens2words(tokens, seq, token_prefix=\"##\"):\n",
    "    \"\"\"\n",
    "    Utility function to aggregate 'seq' on word-level based on 'tokens'\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = []\n",
    "    for token, x in zip(tokens, seq):\n",
    "        if token.startswith(token_prefix):\n",
    "            if type(x) == str:\n",
    "                x = x.replace(token_prefix,\"\")\n",
    "            tmp[-1] += x\n",
    "        else:\n",
    "            if type(x) == str:\n",
    "                tmp.append(x)\n",
    "            else:\n",
    "                tmp.append(x.item())\n",
    "\n",
    "    return tmp if type(tmp[-1]) == str else torch.tensor(tmp, device=device)\n",
    "\n",
    "def add_attributions_to_visualizer_ig(attributions, pred, pred_ind, label, tokens, delta, vis_data_records):\n",
    "    vis_data_records.append(viz.VisualizationDataRecord(\n",
    "                            attributions/attributions.norm(),\n",
    "                            pred,\n",
    "                            pred_ind,\n",
    "                            label,\n",
    "                            pred_ind,\n",
    "                            attributions.sum(),       \n",
    "                            tokens,\n",
    "                            delta)) \n",
    "\n",
    "def input_ref(sentence):\n",
    "    input_ids = torch.tensor(sentence, device=device)\n",
    "    \n",
    "    ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
    "    baseline = input_ids.clone()\n",
    "    baseline[:,1:-1] = ref_token_id \n",
    "    return input_ids, baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_wrapper = BertModelWrapper(model)\n",
    "\n",
    "lig = LayerIntegratedGradients(bert_model_wrapper, bert_model_wrapper.model.bert.embeddings)\n",
    "# accumalate couple samples in this array for visualization purposes\n",
    "vis_data_records_ig = []\n",
    "\n",
    "bert_model_wrapper.eval()\n",
    "bert_model_wrapper.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 1500\n",
    "input_ids, baseline = input_ref(input_ids)\n",
    "\n",
    "pred = bert_model_wrapper(input_ids)\n",
    "pred_label = pred.argmax()\n",
    "pred_p = pred[0, pred_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions, delta = lig.attribute(inputs=input_ids, n_steps=n_steps,\n",
    "                                    baselines=baseline,\n",
    "                                    internal_batch_size=16,\n",
    "                                    return_convergence_delta=True,\n",
    "                                    target=pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('pred: ', pred_label.item(), '(', '%.2f' % pred_p.item(), ')', ', delta: ', abs(delta.item()))\n",
    "\n",
    "# storing couple samples in an array for visualization purposes\n",
    "att = attributions.sum(dim=2).squeeze(0)\n",
    "#attributions = attributions / torch.norm(attributions)\n",
    "att = att.detach().cpu().clone().numpy()\n",
    "\n",
    "att = tokens2words(input_tokens, att)\n",
    "\n",
    "add_attributions_to_visualizer_ig(att, pred_p, pred_label, label, input_words, delta, vis_data_records_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.visualize_text(vis_data_records_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-program",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
