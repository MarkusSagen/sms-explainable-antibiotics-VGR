{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import shap\n",
    "import argparse\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForPreTraining,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AlbertForSequenceClassification,\n",
    "    MT5ForConditionalGeneration,\n",
    "    AutoModelWithLMHead,\n",
    "    AutoTokenizer,\n",
    "    AlbertTokenizer,\n",
    "    T5Tokenizer,\n",
    "    PretrainedConfig,\n",
    "    PreTrainedTokenizer,\n",
    ")\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_bert = 'mt5'\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/mt5-small\")\n",
    "model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"../models/\"+kb_bert+\".pt\"))\n",
    "model = model.to(device)\n",
    "\n",
    "vis_data_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 0\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "df = pd.read_csv(\"../data/seq_dataset.csv\")\n",
    "df.columns = ['text', 'label']\n",
    "random = df.iloc[np.random.permutation(len(df))]\n",
    "train = random.iloc[:round(len(df)*.8)]\n",
    "test = random.iloc[round(len(df)*.8):]\n",
    "test.to_csv('../data/test2_seq.csv', index = False)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AntibioticsDataset(Dataset):\n",
    "    def __init__(self, text, labels, tokenizer, max_len):\n",
    "        self.text = text\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.text[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "            )\n",
    "        \n",
    "        encoding_labels = self.tokenizer.encode_plus(\n",
    "            label,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'            \n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'text':text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': label,\n",
    "            'labels_ids': encoding_labels['input_ids'].flatten()\n",
    "        }\n",
    "\n",
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = AntibioticsDataset(\n",
    "        text=df.text.to_numpy(),\n",
    "        labels=df.label.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "        )\n",
    "\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = create_data_loader(test, tokenizer, 512, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(input_ids, attention_mask=None, batch_size=64, label=None):\n",
    "    \"\"\"\n",
    "    Wrapper function for a Huggingface Transformers model into the format that KernelSHAP expects,\n",
    "    i.e. where inputs and outputs are numpy arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    input_ids = torch.tensor(input_ids, device=device)\n",
    "    attention_mask = torch.ones_like(input_ids, device=device) if attention_mask is None else torch.tensor(attention_mask, device=device)\n",
    "\n",
    " \n",
    "    ds = torch.utils.data.TensorDataset(input_ids.long(), attention_mask.long())\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_size=batch_size)\n",
    "    probas = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            out = model.generate(batch[0], attention_mask=batch[1])\n",
    "            generated = out.clone().detach()\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated]\n",
    "            preds = [1 if p=='Positive' else 0 for p in preds]\n",
    "            preds = torch.tensor(preds)\n",
    "            probas.append(preds)\n",
    "\n",
    "    predictions = torch.cat(probas, dim=0).detach().cpu().clone().numpy()\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def tokens2words(tokens, seq, token_prefix=\"##\"):#\"‚ñÅ\"):\n",
    "    \"\"\"\n",
    "    Utility function to aggregate 'seq' on word-level based on 'tokens'\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = []\n",
    "    for token, x in zip(tokens, seq):\n",
    "        if token.startswith(token_prefix):\n",
    "            if type(x) == str:\n",
    "                x = x.replace(token_prefix,\"\")\n",
    "            tmp[-1] += x\n",
    "        else:\n",
    "            if type(x) == str:\n",
    "                tmp.append(x)\n",
    "            else:\n",
    "                tmp.append(x.item())\n",
    "\n",
    "    return tmp if type(tmp[-1]) == str else torch.tensor(tmp, device=device)\n",
    "\n",
    "def add_attributions_to_visualizer(attributions, pred, pred_ind, label, tokens, delta, vis_data_records):\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    vis_data_records.append(viz.VisualizationDataRecord(\n",
    "                            attributions/attributions.norm(),\n",
    "                            pred,\n",
    "                            pred_ind,\n",
    "                            label,\n",
    "                            pred_ind,\n",
    "                            attributions.sum(),       \n",
    "                            tokens,\n",
    "                            delta)) \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 500\n",
    "torch.cuda.empty_cache()\n",
    "idx = 1\n",
    "#idx = np.random.choice(test_dataset.__len__())\n",
    "print(idx)\n",
    "ref_token = tokenizer.pad_token_id # Could also consider <UNK> or <PAD> tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = test_dataset.__getitem__(idx)\n",
    "input_text = input_x['text']\n",
    "label = input_x['labels']\n",
    "input_ids = input_x['input_ids'].unsqueeze(0)\n",
    "attention_mask = input_x['attention_mask'].unsqueeze(0)\n",
    "\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "input_words = tokens2words(input_tokens, input_tokens)\n",
    "#pred = predict_fn(input_ids=input_ids, attention_mask=attention_mask)\n",
    "pred = predict_fn(input_ids=input_ids)\n",
    "pred_p = pred\n",
    "pred_label = pred_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = input_ids.detach().cpu().clone().numpy()\n",
    "baseline_attn = np.zeros_like(input_ids)\n",
    "\n",
    "# Keep CLS and SEP tokens fixed in baseline\n",
    "baseline[:,1:-1] = ref_token\n",
    "#baseline_attn[:, 0] = 1\n",
    "#baseline_attn[:, -1] = 1\n",
    "\n",
    "explainer = shap.KernelExplainer(predict_fn, baseline)\n",
    "#explainer_attn = shap.KernelExplainer(predict_fn_label_attn, baseline_attn)\n",
    "\n",
    "phi = explainer.shap_values(input_ids.detach().cpu().clone().numpy(), nsamples=500)\n",
    "phi_words = tokens2words(input_tokens, phi.squeeze())\n",
    "\n",
    "phi.shape\n",
    "explainer.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_attributions_to_visualizer(phi_words, float(pred_p), pred_label,[1 if label=='Positive' else 0][0], input_words, None, vis_data_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.visualize_text(vis_data_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn_label = functools.partial(predict_fn, label=1)\n",
    "ref_token = tokenizer.pad_token_id\n",
    "input_x = test_dataset[\"train\"]\n",
    "nsamples = 500\n",
    "\n",
    "shap_val = []\n",
    "for i in range(len(input_x)):\n",
    "    input_ids = input_x['input_ids'][i].unsqueeze(0)\n",
    "    baseline = input_ids.detach().cpu().clone().numpy()\n",
    "    baseline[:,1:-1] = ref_token\n",
    "\n",
    "    explainer = shap.KernelExplainer(predict_fn_label, baseline)\n",
    "    phi = explainer.shap_values(input_ids.detach().cpu().clone().numpy(), nsamples=nsamples)\n",
    "    shap_val.append(phi)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Store data (serialize)\n",
    "with open('../data/'+ kb_bert +'.pickle', 'wb') as handle:\n",
    "    pickle.dump(shap_val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Load data (deserialize)\n",
    "with open('../data/'+ kb_bert +'.pickle', 'rb') as handle:\n",
    "    unserialized_data = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.convert_ids_to_tokens(baseline[0])\n",
    "#model.config.output_hidden_states = True\n",
    "#attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "\"\"\"input_ids = input_x['input_ids'][-1].unsqueeze(0)\n",
    "\n",
    "input_ids = torch.tensor(input_ids, device=device)\n",
    "attention_mask = torch.ones_like(input_ids, device=device)\n",
    "\n",
    "output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "logits = output.logits\n",
    "hidden_states = output.hidden_states\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = []\n",
    "features = {}\n",
    "for i in range(len(input_x)):\n",
    "    input_ids = input_x['input_ids'][i]\n",
    "    input_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    input_words = tokens2words(input_tokens, input_tokens)\n",
    "    phi_words = tokens2words(input_tokens, shap_val[i][0])\n",
    "    for j in range(len(input_words)):\n",
    "        if input_words[j] in features.keys():\n",
    "            old_val = features[input_words[j]]\n",
    "            features[input_words[j]] = ((phi_words[j]).item() + old_val[0], old_val[1]+1)\n",
    "        else:\n",
    "            features[input_words[j]] = ((phi_words[j]).item(), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: v for k, v in sorted(features.items(), key=lambda item: item[1][0], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-europe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
