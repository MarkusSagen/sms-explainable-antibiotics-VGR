{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "223394f8-4d0c-4315-b75c-f66c982bb914",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)   \n",
    "This notebook illustates how NER was used to identify names, organizations, locations, and more   \n",
    "NER was used to identify and remove patient and doctor names for annonymization\n",
    "NER was also used to remove names of locations, since it was found using explainability methods (SHAP, see following notebooks), that models overfitted to place high emphazis on the regions patients were admitted to   \n",
    "  \n",
    "The NER model uses Huggingface Transformers models released by the royal library of Sweden (KB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, pipeline\n",
    "from datasets import load_dataset\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 0\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "df = pd.read_csv(\"../data/dataset_no_recipe.csv\")\n",
    "df.columns = ['text', 'label']\n",
    "df.to_csv('../data/dataset_entity.csv', index = False)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline('ner', model='KB/bert-base-swedish-cased-ner', tokenizer='KB/bert-base-swedish-cased-ner', device=0)\n",
    "\n",
    "res = nlp('Idag släpper KB tre språkmodeller. Jenny Petersson is a dentist for 4654548165.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in res:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity(text, l):\n",
    "    for token in nlp(text):\n",
    "        if token['word'].startswith('##'):\n",
    "            l[-1]['word'] += token['word'][2:]\n",
    "        else:\n",
    "            l += [ token ]\n",
    "    return l\n",
    "\n",
    "def check_len(text):\n",
    "    half = int(len(text)/2)\n",
    "    while text[half]!= ' ':\n",
    "        half -= 1\n",
    "    #print(len(text), half)\n",
    "    return text[:half], text[half:]\n",
    "\n",
    "l = []\n",
    "for text in tqdm(df['text']):\n",
    "    sentences = text.split('.')\n",
    "    for sentence in sentences:\n",
    "        if len(sentence)>1000 and len(sentence)<4000:\n",
    "            half1, half2 = check_len(sentence)\n",
    "            l = entity(half1,l)\n",
    "            l = entity(half2,l)\n",
    "        elif len(sentence)>4000:\n",
    "            half1, half2 = check_len(sentence)\n",
    "            half11, half12 = check_len(half1)\n",
    "            half21, half22 = check_len(half2)\n",
    "            l = entity(half11,l)\n",
    "            l = entity(half12,l)\n",
    "            l = entity(half21,l)\n",
    "            l = entity(half22,l)\n",
    "            \n",
    "        else:\n",
    "            l = entity(sentence,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'][6053]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "dict = {}\n",
    "for tok in l:\n",
    "    if tok['entity'] == 'PER' and tok['score'] >.95:\n",
    "        dict[tok['word']] = tok['score']\n",
    "        names.append(tok['word'])\n",
    "    \n",
    "unique_names = list(dict.fromkeys(names))\n",
    "print(unique_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dict.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in unique_names:\n",
    "    if len(name) == 1:\n",
    "        unique_names.remove(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_names.remove('Pat')\n",
    "unique_names.remove('Akut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "i=0\n",
    "top = 30\n",
    "top_dict = {}\n",
    "for k,v in sorted(dict.items(), key=lambda item:item[1], reverse=True):\n",
    "    if i==top:\n",
    "        break\n",
    "    if k != 'Pat' and k != 'Akut':\n",
    "        top_dict[k] = v\n",
    "        i+=1\n",
    "\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.barh(np.arange(top),top_dict.values(), color='c')\n",
    "ax.set_yticks(np.arange(top))\n",
    "ax.set_yticklabels(top_dict.keys())\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Score\")\n",
    "ax.set_title(\"Top names\")\n",
    "plt.xlim([.9998,0.99992])\n",
    "plt.savefig('names.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-british",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
