{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import shap\n",
    "import argparse\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForPreTraining,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AlbertForSequenceClassification,\n",
    "    MT5ForConditionalGeneration,\n",
    "    AutoModelWithLMHead,\n",
    "    AutoTokenizer,\n",
    "    AlbertTokenizer,\n",
    "    T5Tokenizer,\n",
    "    PretrainedConfig,\n",
    "    PreTrainedTokenizer,\n",
    ")\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "el = 'KB/electra-base-swedish-cased-discriminator'\n",
    "#kb_bert = 'KB/bert-base-swedish-cased'\n",
    "#kb_bert = 'KB/electra-base-swedish-cased-discriminator'\n",
    "kb_bert =  'xlm-roberta-base'\n",
    "\n",
    "with open('../models/'+ el +'.pickle', 'rb') as handle:\n",
    "    electra = pickle.load(handle)\n",
    "    \n",
    "#with open('../models/'+kb_bert+'.pickle', 'rb') as handle:\n",
    "with open('../models/'+ kb_bert +'.pickle_names', 'rb') as handle:\n",
    "    bert = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 0\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "df = pd.read_csv(\"../data/dataset_no_recipe.csv\")\n",
    "df.columns = ['text', 'label']\n",
    "random = df.iloc[np.random.permutation(len(df))]\n",
    "train = random.iloc[:round(len(df)*.8)]\n",
    "test = random.iloc[round(len(df)*.8):]\n",
    "#test.to_csv('../data/test2_names.csv', index = False)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kb_bert = 'KB/bert-base-swedish-cased'\n",
    "#kb_bert = 'KB/electra-base-swedish-cased-discriminator'\n",
    "tokenizer = AutoTokenizer.from_pretrained(kb_bert)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "#test_dataset = load_dataset(\"csv\", data_files='../data/test2_names.csv')\n",
    "test_dataset = load_dataset(\"csv\", data_files='../data/test2.csv')\n",
    "test_ind = test_dataset\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], max_length = 512, add_special_tokens = True)\n",
    "\n",
    "test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens2words(tokens, seq, token_prefix=\"##\"):\n",
    "    \"\"\"\n",
    "    Utility function to aggregate 'seq' on word-level based on 'tokens'\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = []\n",
    "    for token, x in zip(tokens, seq):\n",
    "        if token.startswith(token_prefix):\n",
    "            if type(x) == str:\n",
    "                x = x.replace(token_prefix,\"\")\n",
    "            tmp[-1] += x\n",
    "        else:\n",
    "            if type(x) == str:\n",
    "                tmp.append(x)\n",
    "            else:\n",
    "                tmp.append(x.item())\n",
    "\n",
    "    return tmp if type(tmp[-1]) == str else torch.tensor(tmp, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = test_dataset['train']\n",
    "input_text = input_x['text']\n",
    "label = input_x['label']\n",
    "input_ids = input_x['input_ids']\n",
    "\n",
    "#pred = predict_fn(input_ids, output_logits=True)\n",
    "#sns.distplot(pred[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens2wordssentence(tokens, seq, token_prefix=\"â–\"):\n",
    "    \"\"\"\n",
    "    Utility function to aggregate 'seq' on word-level based on 'tokens'\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = []\n",
    "    for token, x in zip(tokens, seq):\n",
    "        if token.startswith(token_prefix):\n",
    "            if type(x) == str:\n",
    "                x = x.replace(token_prefix,\" \")\n",
    "            if type(x) == str:\n",
    "                tmp.append(x)\n",
    "            else:\n",
    "                tmp.append(x.item())\n",
    "                \n",
    "        elif not token.startswith(\" \"):\n",
    "            if type(x) == str:\n",
    "                x = x.replace(\" \",\"\")\n",
    "            if len(tmp)>0:\n",
    "                tmp[-1] += x\n",
    "        else:\n",
    "            if type(x) == str:\n",
    "                tmp.append(x)\n",
    "            else:\n",
    "                tmp.append(x.item())\n",
    "                \n",
    "    if len(tmp)==0:\n",
    "        print(tokens,tmp)\n",
    "    \n",
    "    return tmp if type(tmp[-1]) == str else torch.tensor(tmp, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-prison",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-cologne",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_val=bert\n",
    "\n",
    "input_tokens = []\n",
    "features = {}\n",
    "absol = {}\n",
    "for i in range(len(input_x)):\n",
    "    input_ids = input_x['input_ids'][i]\n",
    "    input_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    input_words = tokens2wordssentence(input_tokens, input_tokens)\n",
    "    phi_words = tokens2wordssentence(input_tokens, shap_val[i][0])\n",
    "    for j in range(len(input_words)):\n",
    "        if input_words[j] in features.keys():\n",
    "            old_val = features[input_words[j]]\n",
    "            features[input_words[j]] = ((phi_words[j]).item() + old_val[0], old_val[1]+1)\n",
    "            absol[input_words[j]] = (np.abs((phi_words[j]).item()) + old_val[0], old_val[1]+1)\n",
    "        else:\n",
    "            features[input_words[j]] = ((phi_words[j]).item(), 1)\n",
    "            absol[input_words[j]] = (np.abs((phi_words[j]).item()), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-compromise",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: v for k, v in sorted(features.items(), key=lambda item: item[1][0], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "i=0\n",
    "top = 20\n",
    "top_dict = {}\n",
    "for k,v in sorted(features.items(), key=lambda item:item[1][0], reverse=True):\n",
    "    if i==top:\n",
    "        break\n",
    "    if k != ' [PAD]' and k != ' 1' and k != '46' and k != ' .' and k != ',' and k != '(' and k != ')' and k != '7' and k != ':' and k != 'i':\n",
    "        top_dict[k] = v[0]\n",
    "        i+=1\n",
    "\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.barh(np.arange(top),top_dict.values(), color='limegreen')\n",
    "ax.set_yticks(np.arange(top))\n",
    "ax.set_yticklabels(top_dict.keys())\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Global shap values\")\n",
    "ax.set_title(\"Top words for antibiotics prescription\")\n",
    "plt.savefig('top_ab_words.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "top = 20\n",
    "top_dict = {}\n",
    "for k,v in sorted(features.items(), key=lambda item:item[1][0], reverse=False):\n",
    "    if i==top:\n",
    "        break\n",
    "    if k != ':' and k != '-' and k != '.' and k != '/' and k != '%' and k != '0' and k != ',':\n",
    "        top_dict[k] = -v[0]\n",
    "        i+=1\n",
    "\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.barh(np.arange(top),top_dict.values(), color='r')\n",
    "ax.set_yticks(np.arange(top))\n",
    "ax.set_yticklabels(top_dict.keys())\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Global shap values\")\n",
    "ax.set_title(\"Top words for not prescribing antibiotics\")\n",
    "plt.savefig('top_noab_words.png', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "top = 20\n",
    "top_dict = {}\n",
    "for k,v in sorted(absol.items(), key=lambda item:item[1][0], reverse=True):\n",
    "    if i==top:\n",
    "        break\n",
    "    if k != ':' and k != '-' and k != '.' and k != '/' and k != '%' and k != '0' and k != '1' and k != '26':\n",
    "        top_dict[k] = v[0]\n",
    "        i+=1\n",
    "\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.barh(np.arange(top),top_dict.values(), color='b')\n",
    "ax.set_yticks(np.arange(top))\n",
    "ax.set_yticklabels(top_dict.keys())\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Global shap values\")\n",
    "ax.set_title(\"Top words \")\n",
    "plt.savefig('top_words.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-trailer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
